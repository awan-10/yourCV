= Ammar Ahmad Awan
:showtitle!:
:address: 2015 Neil Ave. • Columbus • OH 43210 • USA
:contact: +1 614 360 8349 • ammar.ahmad.awan@gmail.com
:website: http://cse.osu.edu/~awan.10

_{address}_ +
_{contact}_ +
_{website}_

== Research Interests

My broad interests lie at the interesection of High
Performance Computing (HPC) and Machine Learning (ML). I am
actively investigating new approaches to improve performance
and productivity of scalable software systems for HPC and
ML.

== Education

*The Ohio State University (OSU), Columbus, Ohio, USA*

Ph.D. in Computer Science and Engineering, Aug 2014—May 2020 (Expected)

Advisor: http://cse.osu.edu/~panda/[D.K. Panda] • CGPA: 3.68/4.0

Thesis: Co-designing MPI Middleware and DL Frameworks for
High-Performance DNN Training on HPC Systems

'''

*Kyung Hee University (KHU), Suwon, South Korea*

Master of Computer Engineering, 2011—2013 

Advisor: http://uclab.khu.ac.kr/index_professor.php?ckattempt=1[Sungyoung Lee] • CGPA: 4.22/4.3

Thesis: Efficient Support for Parallel File Access in Java HPC
 
'''

*National University of Sciences and Technology (NUST), Islamabad, Pakistan*

Bachelor of Information Technology, 2004—2008                       

Advisor: https://scholar.google.com.pk/citations?user=V0XEUMAAAAAJ&hl=en[Aamir Shafi] • CGPA: 3.71/4.0

Final Project: Optimizing N-body Simulations for Multicore Compute Clusters

'''

== Select Publications

_I am the lead author of the following publications._

. *A. A. Awan*, K. V. Manian, C-H Chu, H. Subramoni, and DK
Panda, _Optimized Large-Message Broadcast for Deep Learning
Workloads: MPI, MPI+NCCL, or NCCL2?_, Parallel Computing 
(*PARCO '19*), Vol. 85, Pages 141-152, Jul 2019.

. *A. A. Awan*, C-H Chu, X. Lu, H. Subramoni, and D. K. Panda,
_OC-DNN: Exploiting Advanced Unified Memory Capabilities in
CUDA 9 and Volta GPUs for Out-of-Core DNN Training_, 25th
IEEE International Conference on High-Performance Computing,
Data, Analytics, and Data Science (*HiPC '18*) '18, Dec 2018.

. *A. A. Awan*, C-H Chu, X. Lu, H. Subramoni, and DK Panda,
_Can Unified-Memory support on Pascal and Volta GPUs enable
Out-of-Core DNN Training?_, ISC High-Performance (*ISC
'18*), June 2018. *Best Student Poster Award*.

. *A. A. Awan*, K. Hamidouche, J. Hashmi, and D. K. Panda,
_S-Caffe: Co-designing MPI Runtimes and Caffe for Scalable
Deep Learning on Modern GPU Clusters_, 22nd ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming
(*PPoPP '17*), Feb 2017.

. *A. A. Awan*, K. Hamidouche, A. Venkatesh, and D. K. Panda,
_Efficient Large Message Broadcast using NCCL and CUDA-Aware
MPI for Deep Learning_, 23rd European MPI Users' Group
Meeting (*EuroMPI '16*), Sep 2016. *Best Paper Runner-Up*.


== Awards and Distinctions

. _IEEE TCHPC Travel Award_ for presenting Doctoral Showcase at SC ’19.
. _ACM Student Travel Award_ for participating in ACM Student Research Competition at SC ’17.
. _NSF Student Travel Award_ for presenting S-Caffe at ACM PPoPP ‘17.
. _Student Travel Award_ for presenting Tutorial at HotI ’17.
. _Best Student Poster Award_ at ISC High-Performance Event (ISC ’19).
. _Best Paper Runner-up_ at EuroMPI 2016, Edinburgh, UK.
. _O’Donnell Fellowship_ (5/1,400 applicants) for
first year of Ph.D. studies at The Ohio State University
(2015).
. _Global IT Talents Scholarship_ for Masters Degree in South Korea (2011 - 2013).
. _President’s Gold Medal_ for highest CGPA in Bachelors Degree (NUST - 2008).
. _Rector’s Gold Medal_ for Best Final Year Project (NUST - 2008).
. _Best Industry Project Award_ for the Final Year Project at NUST-SEECS Open House '08.
. _Merit Scholarship_ for 7 out of 8 semesters at NUST. (Awarded to students with 3.5 and above GPA).
. _Third Prize_ for presenting Project: Constella Platinum at All Pakistan software competition - Softcom '06.
. _Student Volunteer_ for SC ‘08, USA. (Selected but couldn’t travel).


== Research and Development Experience

* *Network Based Computing Lab (http://nbcl.cse.ohio-state.edu) at The Ohio State University*

** Graduate Research Assistant (Aug ‘14 – present)

*** Investigate Collective Communication Designs and
Implementations for CUDA-Aware MPI libraries like _MVAPICH2_
and _MVAPICH2-GDR_.
*** Co-design Deep Learning frameworks like Caffe and MPI
runtimes like _MVAPICH2_ to enable efficient distributed Deep Learning on modern GPU clusters.
*** Utilize existing benchmark suites like OSU Microbenchmarks (OMB), Intel MPI benchmarks (IMB) and test suites like MPICH tests, Intel tests, etc. to rigorously test and evaluate new designs on multiple HPC systems with diverse set of CPU and GPU architectures.
*** Perform regression/sanity testing on software stacks
that are released periodically as new features from several
research students and staff are developed and pushed to the
main _MVAPICH2_ codebase.
*** Design new benchmarks to evaluate the capabilities of the MVAPICH2 MPI library as well as OSU-Caffe and other DL stacks like Horovod for TensorFlow and PyTorch on large-scale HPC systems.

Note: _MVAPICH2_ is a popular and open-source MPI
Library being used by more than 3,000 organizations around
the world. It has been downloded 613,000 times directly from
the project site (http://mvapich.cse.ohio-state.edu).
 
* *X-Scale Solutions (http://x-scalesolutions.com), Columbus, OH*

** Research Intern (May ‘19—Aug ’19)

*** Conducted in-depth performance characterization of
TensorFlow/Horovod on Large Scale HPC Systems like Summit
(#1 on Top500) and Sierra (#2 on Top500) using X-ScaleAI.

*** Implemented one-click installers for X-Scale products
(X-ScaleAI and X-ScaleHPC).
 
* *Microsoft Research (MSR), Redmond, WA*

** Research Intern with the RiSE Group at MSR (May ’18 – Aug’18)

*** Mentors: Madan Musuvathi, Todd Mytkowicz, and Saeed Maleki.
*** Assisted in design and evaluation of
semantics-preserving SGD codes that scale to hundreds of
CPUs.
*** Designed and developed code/experiments to evaluate
Criteo’s Ad-click prediction at scale using TensorFlow on Cloud-based systems like Google Cloud ML, Amazon SageMaker, and Azure BatchAI.
 

* *iFaST Solutions Pvt. Ltd, Peshawar, Pakistan*

** Vice President: Innovation (Jun ‘13 – Jun ‘14)

*** Developed tutorials and delivered talks on Version
Control (Git) and use of PHP frameworks (CodeIgniter) to
transform internal processes. This helped to avoid software
development delays faced by the company.
 
* *Ubiquitous Computing Laboratory, Kyung Hee University, South Korea*

** Graduate Research Assistant (Aug ‘11 – Jun ‘13)
*** Co-founded the HPC over Cloud (HPCoC) project for the team.
*** Published two papers on Parallel I/O for Java HPC project.
 
* *Skylight Software Inc., CA and Islamabad, Pakistan*

** Principle Software Engineer (Apr ‘11 – Jul ‘11)

*** Designed and implemented a state-charts based approach for developing efficient custom controls for a new document format proposed by Skylight.
 
* *NUST-SEECS, Pakistan (Feb ‘08 – Nov ‘09) / University of Reading, UK (Feb ‘09 – Jun ‘09)*

** Research Assistant

*** Analyzed and profiled performance of Gadget-2 code and proposed hybrid-parallelism to speed-up the simulations on multi-core clusters.

== Teaching and Mentoring Experience

* Mentored undergradute and graduate students at The Ohio State University to work on various research and development projects.

** Arpan Jain, Ph.D. student at OSU 
** Quentin Anthony, Ph.D. Student at OSU
** Vardaan Gangal, B.S Student at OSU

* Mentored seven prospective M.S and Ph.D. students for GradAppLab (http://gradapplab.pk)

* Developed and designed the overall curriculum, lectures, homework assignments, and labs for special-topic graduate course at OSU: _CSE 5194.01: Introduction to High Performance Deep Learning_ (Autumn '18 and Autumn '19)

== All Publications

_Most updated list of publications is available from my https://scholar.google.com/citations?user=JM_IZzQAAAAJ&hl=en[Google Scholar] page._

===  Journal Articles
 
. *A. A. Awan*, A. Jain, C-H Chu, H. Subramoni, and DK Panda,
_Communication Profiling and Characterization of Deep
Learning Workloads on Clusters with High-Performance
Interconnects_, IEEE Micro (Early Access: doi:
10.1109/MM.2019.2949986).
 
. *A. A. Awan*, K. V. Manian, C-H Chu, H. Subramoni, and DK
Panda, _Optimized Large-Message Broadcast for Deep Learning
Workloads: MPI, MPI+NCCL, or NCCL2?_, Parallel Computing
(PARCO '19), Vol. 85, Pages 141-152, July 2019.
 
. C-H Chu, X. Lu, *A. A. Awan*, H. Subramoni, Bracy Elton, and
DK Panda, _Exploiting Hardware Multicast and GPUDirect RDMA
for Efficient Broadcast_, IEEE Transactions on Parallel and
Distributed Systems (TPDS '19), Vol. 30, No. 3, Pages
575-588, Mar 2019.
 
. K. Hamidouche, A. Venkatesh, *A. A. Awan*, H. Subramoni, and D. K. 
Panda, _CUDA-Aware OpenSHMEM: Extensions and Designs
for High Performance OpenSHMEM on GPU Clusters_, Parallel
Computing (PARCO '16), Vol. 58, Pages 27-36, Oct 2016.

. Z. Pervez, *A. A. Awan*, A. M. Khattak, S. Y. Lee, and
Eui-Nam Huh, _Privacy-aware searching with oblivious term
matching for cloud storage_, Journal of Supercomputing, Vol.
63, Issue 2, Pages 538–560, Feb 2013.
 
=== Refereed Conference/Workshop Papers
 
. A. Jain, *A. A. Awan*, H. Subramoni, and DK Panda, _Scaling
TensorFlow, PyTorch, and MXNet using MVAPICH2 for
High-Performance Deep Learning on Frontera_, 3rd Deep
Learning on Supercomputers Workshop, held in
conjunction with SC ‘19, Nov 2019.
 
. A. Jain, *A. A. Awan*, Q. Anthony, H. Subramoni, and DK
Panda, _Performance Characterization of DNN Training using
TensorFlow and PyTorch on Modern Clusters_, 21st IEEE
International Conference on Cluster Computing, (Cluster
'19), Sep 2019.

. *A. A. Awan*, A. Jain, C-H Chu, H. Subramoni, and D. K.
Panda, _Communication Profiling and Characterization of Deep
Learning Workloads on Clusters with High-Performance
Interconnects_, 26th Symposium on High-Performance
Interconnects (HotI ’19), Aug 2019.
 
. *A. A. Awan*, J. Bedorf, C-H Chu, H. Subramoni, and D. K. Panda, 
_Scalable Distributed DNN Training using TensorFlow and
CUDA-Aware MPI: Characterization, Designs, and Performance
Evaluation_, 19th IEEE/ACM International Symposium on
Cluster, Cloud and Grid Computing (CCGrid '19), May 2019.

 
. K. Vadambacheri Manian, *A. A. Awan*, A. Ruhela, C. Chu, 
and D. K. Panda, _Characterizing CUDA Unified Memory (UM)-Aware
MPI Designs on Modern GPU Architectures_, 12th Workshop on
General Purpose Processing Using GPU (GPGPU '19), held in
conjunction with
ASPLOS '19, Apr 2019.
 
. *A. A. Awan*, C-H Chu, X. Lu, H. Subramoni, and D. K. Panda,
_OC-DNN: Exploiting Advanced Unified Memory Capabilities in
CUDA 9 and Volta GPUs for Out-of-Core DNN Training_, IEEE
25th International Conference on High Performance Computing
(HiPC '18), Dec 2018.

. *A. A. Awan*, C-H Chu, H. Subramoni, D. K. Panda, _Optimized
Broadcast for Deep Learning Workloads on Dense-GPU
InfiniBand Clusters: MPI or NCCL?_, 25th European MPI Users'
Group Meeting (EuroMPI '18), Sep 2018.
 
. *A. A. Awan*, H. Subramoni, D. K. Panda, _An In-depth
Performance Characterization of CPU- and GPU-based DNN
Training on Modern Architectures_, 3rd Workshop on Machine
Learning in HPC Environments (MLHPC ‘17), held in
conjunction with SC ’17, Nov 2017.
 
. C-H Chu, X. Lu, *A. A. Awan*, H. Subramoni, J. Hashmi, Bracy
Elton, and DK Panda, _Efficient and Scalable Multi-Source
Streaming Broadcast on GPU Clusters for Deep Learning_,
46th International Conference on Parallel Processing (ICPP '17), Aug
2017.
 
. *A. A. Awan*, K. Hamidouche, J. Hashmi, and D. K. Panda,
_S-Caffe: Co-designing MPI Runtimes and Caffe for Scalable
Deep Learning on Modern GPU Clusters_, 22nd ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming
(PPoPP '17), Feb 2017.

. K. Hamidouche, *A. A. Awan*, A. Venkatesh, and D. K. Panda,
_CUDA M3: Designing Efficient CUDA Managed Memory-aware MPI
by Exploiting GDR and IPC_, 23rd IEEE International
Conference on High Performance Computing, Data, and
Analytics, Dec 2016.
 
. *A. A. Awan*, K. Hamidouche, A. Venkatesh, and D. K. Panda,
_Efficient Large Message Broadcast using NCCL and CUDA-Aware
MPI for Deep Learning_, 23rd European MPI Users' Group
Meeting (EuroMPI ‘16), Sep 2016. *Best Paper Runner-Up*.
 
. C. Chu, K. Hamidouche, A. Venkatesh, *A. A. Awan*, and D. K.
Panda, _CUDA Kernel based Collective Reduction Operations on
Large-scale GPU Clusters_, 16th IEEE/ACM International
Symposium on Cluster, Cloud and Grid Computing (CCGrid
‘16), May 2016.
 
. *A. A. Awan*, K. Hamidouche, A. Venkatesh, J. Perkins, H.
Subramoni, and D. K. Panda, _GPU-Aware Design,
Implementation, and Evaluation of Non-blocking Collective
Benchmark_, 22nd European MPI Users' Group
Meeting (EuroMPI ‘15), Sep 2015.
 
. K. Hamidouche, A. Venkatesh, *A. A. Awan*, H. Subramoni, 
and D. K. Panda, _Exploiting GPUDirect RDMA in Designing High
Performance OpenSHMEM for NVIDIA GPU Clusters_, IEEE
International Conference on Cluster Computing (Cluster '15),
Sep 2015.
 
. *A. A. Awan*, K. Hamidouche, C. Chu, and D. K. Panda, _A
Case for Non-Blocking Collectives in OpenSHMEM: Design,
Implementation, and Performance Evaluation using
MVAPICH2-X_, Workshop on OpenSHMEM and Related Technologies
(OpenSHMEM '15), Aug 2015.
 
. H. Subramoni, *A. A. Awan*, K. Hamidouche, D. Pekurovsky, A.
Venkatesh, S. Chakraborty, K. Tomko, and D. K. Panda,
_Designing Non-Blocking Personalized Collectives with Near
Perfect Overlap for RDMA-Enabled Clusters_, ISC High
Performance (ISC '15), Jul 2015.
 
. S. Chakraborty, H. Subramoni, J. Perkins, *A. A. Awan*, 
and D. K. Panda, _On-demand Connection Management for OpenSHMEM
and OpenSHMEM+MPI_ (HIPS '15), IPDPS Workshop, May 2015.
 
. *A. A. Awan*, M. S. Ayub, A. Shafi and S. Lee, _Towards
Efficient Support for Parallel I/O in Java HPC_, 13th
International Conference on Parallel and Distributed
Computing, Applications and Technologies (PDCAT '12), Dec
2012.
 
. M. B. Amin, W. A. Khan, *A. A. Awan*, and S. Y. Lee,
“Intercloud Message Exchange Middleware”, 6th International
Conference on Ubiquitous Information Management and
Communication (ICUIMC '12), Sep 2012. 

== Posters

. *A. A. Awan* and DK Panda, _Co-designing Communication
Middleware and Deep Learning Frameworks for High-Performance
DNN Training on HPC Systems_, Doctoral Showcase at SC '19,
Nov 2019.


. *A. A. Awan*, H. Subramoni, and DK Panda, _Exploiting CUDA
Unified Memory for Efficient Out-of-Core DNN Training_,
Poster at NVIDIA GTC '19, April 2019.

. *A. A. Awan*, C-H Chu, X. Lu, H. Subramoni, and DK Panda,
_Can Unified-Memory support on Pascal and Volta GPUs enable
Out-of-Core DNN Training?_, ISC High-Performance (ISC '18), 
Jun 2018. *Best Student Poster Award*.

. *A. A. Awan* and DK Panda, _Co-designing MPI Runtimes and
Deep Learning Frameworks for Scalable Distributed Training
on GPU Clusters_, ACM Student Research Competition (SRC)
poster at SC '17, Nov 2017.

. *A. A. Awan*, M. B. Amin, S. Hussain, A. Shafi, S. Y. Lee,
_An MPI-IO Compliant Java based Parallel I/O Library_,
Poster at 13th IEEE/ACM International Symposium on Cluster,
Cloud and Grid Computing (CCGrid '13), May 2013.

== Talks

. _Co-designing Communication
Middleware and Deep Learning Frameworks for High-Performance
DNN Training on HPC Systems_, Doctoral Showcase Presentation
at SC '19, Nov 2019.

. _An In-depth
Performance Characterization of CPU- and GPU-based DNN
Training on Modern Architectures_, MLHPC ‘17, SC '17
Workshop, Nov 2017.

. _S-Caffe: Co-designing MPI Runtimes and Caffe for Scalable
Deep Learning on Modern GPU Clusters_, PPoPP ’17, Feb 2017.

. _Efficient Large Message Broadcast using NCCL and
CUDA-Aware MPI for Deep Learning_, Best Paper Runner-up
Session, EuroMPI ’16 @ EPCC Edinburgh UK, Sep 2016.

. _Why Execution is more important than Ideas_, Invited Talk
at CECOS University, Peshawar, Pakistan, Feb 2014.

== Invited Tutorials
 
_Number of Attendees are in parentheses._

. _High Performance Distributed Deep Learning: A Beginner’s Guide_, NVIDIA GTC ’20 (Accepted; To be presented).
. _High Performance Distributed Deep Learning: A Beginner’s
Guide_, SC ’19, Nov 2019. (120)
. _High Performance Architectures for Distributed Deep
Learning_, MICRO ’19, Oct 13, 2019. (60)
. _HPC Meets Distributed Deep Learning_, Hot Interconnects
(HotI '19), Aug 14, 2019. (50)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, PEARC '19, Jul 29, 2019. (80)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, ISCA '19, Jun 22, 2019. (40)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, ISC '19, Jun 16, 2019. (40)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, CCGrid '19, May 15, 2019. (40)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, NCAR SEA '19, Apr 12, 2019. (10)
. _How to Boost the Performance of HPC/AI Applications Using
MVAPICH2 Library_ NVIDIA GTC '19, Mar 20, 2019. (50)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, NVIDIA GTC '19, Mar 18, 2019. (100)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, PPoPP '19, Feb 17, 2019. (15)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, DOD-PETTT '18, May 15, 2018. (25)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, NCAR SEA '18, Apr 5, 2018. (30)
. _High-Performance Distributed Deep Learning: A Beginner's
Guide_, PPoPP '18, Feb 25, 2018. (20)
. _High-Performance Distributed Deep Learning for Dummies_,
IT4 Innovations (Austria), Jan 24, 2018. (35)
. _High Performance Distributed Deep Learning for Dummies_,
Hot Interconnects (HotI '17) Aug 28, 2017. (50)
 
== Professional Service
 
=== Memberships

. ACM Student Member
. IEEE Student Member
. Message Passing Interface (MPI) Forum 

=== Reviewer

. 34th IEEE International Parallel & Distributed Processing Symposium (IPDPS '20). 
. The FREE Python conference in Columbus (PyOhio ’19).
. 32nd ACM International Conference on Supercomputing (ICS ‘18).
. Intl. Conference on High Performance Computing, Networking, Storage, and Analysis (SC ’17).
. 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID ‘17).
. 26th International Conference on Parallel Architectures and Compilation Techniques (PACT ‘17).
. 31st IEEE International Parallel & Distributed Processing Symposium (IPDPS ‘17).
. ISC High Performance 2016 (ISC ’16).
. Elsevier Journal of Parallel and Distributed Computing.
 
=== Volunteer
. OSU Booth, Supercomputing (SC) '17, '18, and '19.
. MVAPICH Users Group Meeting (MUG) ’16, ’17, and ’19.
. IEEE ICDCS 2015.

== Technical Skills

* Strong programming skills in C and Java (SE)/Java for HPC.
* Development experience in C++ and interaction of C, C\++, and MPI.
* Product-development experience (Skylight Software) using C and Win32 programming.
* Experience of developing parallel programs using OpenMP, MPI and MPJ Express.
* Familiar with C#, ASP.NET, Android SDK, PHP, MySQL, IBM Cell SDK, and PerfAPI (PAPI)/Perfex.
* Understanding of web technologies including HTML, DHTML, CSS, XML, XSLT and XPath.
* Strong communication and presentation skills
** Delivered several elaborate presentations on technical projects like OSU-Caffe, High-Performance Deep Learning (HiDL), MVAPICH2, Constella, Gadget-2, Oil Reservoir Simulators, and MPJ-IO.

== References

. Dhabaleswar Kumar (DK) Panda, Professor.
 
 Dept. of Computer Science and Engineering
 Dreese Lab 785 
 The Ohio State University 
 2015 Neil Avenue 
 Columbus, OH-43210, USA 
 Tel: (614) 292-5199
 Fax: (614) 292-2911
 Email: panda@cse.ohio-state.edu
 Website: http://web.cse.ohio-state.edu/~panda.2/
 Twitter: @dhabalkpanda

. Gagan Agrawal, Professor.

 Dept. of Computer Science and Engineering
 Dreese Lab 781 
 The Ohio State University 
 2015 Neil Avenue 
 Columbus, OH-43210, USA 
 Phone: (614)  688-8450 
 Fax: (614) 292-2911 
 Email: agrawal@cse.ohio-state.edu
 Website: http://web.cse.ohio-state.edu/~agrawal.28/

. Radu Teodorescu, Associate Professor.

 Dept. of Computer Science and Engineering
 Dreese Lab 797 
 The Ohio State University 
 2015 Neil Avenue 
 Columbus, OH-43210, USA 
 Email: teodores@cse.ohio-state.edu
 Website: http://web.cse.ohio-state.edu/~teodorescu.1/
